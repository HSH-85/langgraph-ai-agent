"""
LangGraph RAG ì—ì´ì „íŠ¸ì˜ ë…¸ë“œ í•¨ìˆ˜ë“¤
"""
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
from langchain_core.messages import HumanMessage, AIMessage
from tavily import TavilyClient
from state import AgentState
import cohere
import os
from datetime import datetime
from dotenv import load_dotenv

# í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€
GraphState = AgentState

load_dotenv()

# API í‚¤ í™•ì¸
openai_api_key = os.getenv("OPENAI_API_KEY")
tavily_api_key = os.getenv("TAVILY_API_KEY")

# API í‚¤ í™•ì¸ (ì¡°ìš©í•œ ëª¨ë“œ - í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
# if not openai_api_key:
#     print("âš ï¸ ê²½ê³ : OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
#     print("   .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

# LLM ì´ˆê¸°í™” (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ìë™ìœ¼ë¡œ API í‚¤ë¥¼ ì½ì–´ì˜´)
# api_key íŒŒë¼ë¯¸í„°ë¥¼ ëª…ì‹œí•˜ì§€ ì•Šìœ¼ë©´ OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ì‚¬ìš©
llm = ChatOpenAI(
    model="gpt-4o-mini", 
    temperature=0
)
embeddings = OpenAIEmbeddings()

# Tavily í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
if tavily_api_key:
    tavily_client = TavilyClient(api_key=tavily_api_key)
else:
    tavily_client = None
    # print("âš ï¸ ê²½ê³ : TAVILY_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# Cohere í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ë¦¬ë­í¬ìš©)
cohere_api_key = os.getenv("COHERE_API_KEY")
if cohere_api_key:
    cohere_client = cohere.Client(api_key=cohere_api_key)
else:
    cohere_client = None
    # print("âš ï¸ ê²½ê³ : COHERE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¦¬ë­í¬ ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")


# ì „ì—­ ë³€ìˆ˜: Retriever (ì´ˆê¸°í™” í•„ìš”)
retriever = None


def set_retriever(new_retriever):
    """Retrieverë¥¼ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜"""
    global retriever
    retriever = new_retriever


def analyze_intent(state: AgentState) -> AgentState:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ëŠ” ë…¸ë“œ (ê³ ë„í™”)
    
    Args:
        state: í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ
        
    Returns:
        ì—…ë°ì´íŠ¸ëœ ìƒíƒœ (intent, current_step, thought_process)
    """
    question = state.get("question", "")
    thought_process = state.get("thought_process", [])
    
    # ì˜ë„ ë¶„ì„ í”„ë¡¬í”„íŠ¸
    intent_prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {question}

ì˜ë„ ë¶„ë¥˜:
1. 'factual': ì‚¬ì‹¤ì  ì •ë³´ë‚˜ ì§€ì‹ì„ ë¬»ëŠ” ì§ˆë¬¸ (ì˜ˆ: "íŒŒì´ì¬ì´ë€?", "LangGraph íŠ¹ì§•ì€?")
2. 'analytical': ë¹„êµ, ë¶„ì„, í‰ê°€ë¥¼ ìš”êµ¬í•˜ëŠ” ì§ˆë¬¸ (ì˜ˆ: "Aì™€ Bì˜ ì°¨ì´ëŠ”?", "ì¥ë‹¨ì ì€?")
3. 'conversational': ì¼ë°˜ ëŒ€í™”ë‚˜ ì˜ê²¬ êµí™˜ (ì˜ˆ: "ì•ˆë…•", "ê³ ë§ˆì›Œ")
4. 'procedural': ì ˆì°¨, ë°©ë²•, ì‚¬ìš©ë²•ì„ ë¬»ëŠ” ì§ˆë¬¸ (ì˜ˆ: "ì–´ë–»ê²Œ í•˜ë‚˜ìš”?", "ì„¤ì¹˜ ë°©ë²•ì€?")

ìœ„ 4ê°€ì§€ ì¤‘ í•˜ë‚˜ë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”: """

    try:
        response = llm.invoke(intent_prompt)
        intent = response.content.strip().lower() if hasattr(response, 'content') else "factual"
        
        # ìœ íš¨í•œ ì˜ë„ ê°’ìœ¼ë¡œ ì •ê·œí™”
        valid_intents = ['factual', 'analytical', 'conversational', 'procedural']
        if intent not in valid_intents:
            intent = 'factual'  # ê¸°ë³¸ê°’
            
        thought_process.append(f"ğŸ§  ì˜ë„ ë¶„ì„: {intent}")
    except Exception:
        intent = 'factual'
        thought_process.append("ğŸ§  ì˜ë„ ë¶„ì„: factual (ê¸°ë³¸ê°’)")
    
    return {
        "intent": intent,
        "current_step": "ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...",
        "thought_process": thought_process
    }


def retrieve(state: AgentState) -> AgentState:
    """
    ì§ˆë¬¸ì„ ë°›ì•„ VectorDBì—ì„œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë…¸ë“œ
    
    Args:
        state: í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ
        
    Returns:
        ì—…ë°ì´íŠ¸ëœ ìƒíƒœ (documents í¬í•¨)
    """
    question = state.get("question", "")
    documents = state.get("documents", [])
    thought_process = state.get("thought_process", [])
    
    # Retrieverê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš° ChromaDBì—ì„œ ì§ì ‘ ê²€ìƒ‰
    if retriever is None:
        try:
            vectorstore = Chroma(
                persist_directory="./chroma_db",
                embedding_function=embeddings
            )
            docs = vectorstore.similarity_search(question, k=5)  # ë¦¬ë­í¬ë¥¼ ìœ„í•´ ë” ë§ì´ ê²€ìƒ‰
            documents = [doc.page_content for doc in docs]
            thought_process.append(f"ğŸ“š ë²¡í„° ìŠ¤í† ì–´ ê²€ìƒ‰: {len(documents)}ê°œ ë¬¸ì„œ ë°œê²¬")
        except Exception:
            # ë²¡í„° ìŠ¤í† ì–´ê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ì¡°ìš©íˆ ì²˜ë¦¬)
            documents = []
            thought_process.append("ğŸ“š ë²¡í„° ìŠ¤í† ì–´ ê²€ìƒ‰: ë¬¸ì„œ ì—†ìŒ")
    else:
        # Retrieverë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰
        try:
            docs = retriever.invoke(question)
            documents = [doc.page_content if hasattr(doc, 'page_content') else str(doc) for doc in docs]
            thought_process.append(f"ğŸ“š ë²¡í„° ìŠ¤í† ì–´ ê²€ìƒ‰: {len(documents)}ê°œ ë¬¸ì„œ ë°œê²¬")
        except Exception:
            # Retriever ê²€ìƒ‰ ì˜¤ë¥˜ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ì¡°ìš©íˆ ì²˜ë¦¬)
            documents = []
            thought_process.append("ğŸ“š ë²¡í„° ìŠ¤í† ì–´ ê²€ìƒ‰: ë¬¸ì„œ ì—†ìŒ")
    
    return {
        "documents": documents,
        "current_step": "ë¬¸ì„œ ë¦¬ë­í¬ ì¤‘...",
        "thought_process": thought_process
    }


def rerank_documents(state: AgentState) -> AgentState:
    """
    ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ë¦¬ë­í¬í•˜ì—¬ ê´€ë ¨ì„± ìˆœìœ¼ë¡œ ì¬ì •ë ¬í•˜ëŠ” ë…¸ë“œ (ê³ ë„í™”)
    
    Args:
        state: í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ
        
    Returns:
        ì—…ë°ì´íŠ¸ëœ ìƒíƒœ (ì¬ì •ë ¬ëœ documents)
    """
    question = state.get("question", "")
    documents = state.get("documents", [])
    thought_process = state.get("thought_process", [])
    
    # ë¬¸ì„œê°€ ì—†ê±°ë‚˜ Cohere í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if not documents or len(documents) == 0:
        thought_process.append("ğŸ¯ ë¦¬ë­í¬: ë¬¸ì„œ ì—†ìŒ")
        return {
            "documents": documents,
            "current_step": "ë¬¸ì„œ í‰ê°€ ì¤‘...",
            "thought_process": thought_process
        }
    
    if cohere_client is None:
        thought_process.append(f"ğŸ¯ ë¦¬ë­í¬: ìŠ¤í‚µ (Cohere ë¯¸ì„¤ì •, {len(documents)}ê°œ ìœ ì§€)")
        return {
            "documents": documents,
            "current_step": "ë¬¸ì„œ í‰ê°€ ì¤‘...",
            "thought_process": thought_process
        }
    
    try:
        # Cohere Rerank APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ì¬ì •ë ¬
        # top_n: ìƒìœ„ Nê°œ ë¬¸ì„œë§Œ ë°˜í™˜ (ê¸°ë³¸ê°’: ë¬¸ì„œ ì „ì²´)
        rerank_response = cohere_client.rerank(
            model="rerank-multilingual-v3.0",  # ë‹¤êµ­ì–´ ì§€ì› ëª¨ë¸
            query=question,
            documents=documents,
            top_n=min(len(documents), 3)  # ìµœëŒ€ 3ê°œ ë¬¸ì„œë§Œ ë°˜í™˜
        )
        
        # ì¬ì •ë ¬ëœ ë¬¸ì„œ ì¶”ì¶œ
        # documentsê°€ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ result.documentë„ ë¬¸ìì—´ì…ë‹ˆë‹¤
        reranked_documents = [
            result.document['text'] if isinstance(result.document, dict) and 'text' in result.document
            else str(result.document) if not isinstance(result.document, str)
            else result.document
            for result in rerank_response.results
        ]
        
        thought_process.append(f"ğŸ¯ ë¦¬ë­í¬: {len(documents)}ê°œ â†’ {len(reranked_documents)}ê°œ (ìƒìœ„ ë¬¸ì„œ ì„ íƒ)")
        
        return {
            "documents": reranked_documents,
            "current_step": "ë¬¸ì„œ í‰ê°€ ì¤‘...",
            "thought_process": thought_process
        }
    except Exception as e:
        # ë¦¬ë­í¬ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë¬¸ì„œ ë°˜í™˜
        thought_process.append(f"ğŸ¯ ë¦¬ë­í¬: ì‹¤íŒ¨ ({len(documents)}ê°œ ìœ ì§€)")
        return {
            "documents": documents,
            "current_step": "ë¬¸ì„œ í‰ê°€ ì¤‘...",
            "thought_process": thought_process
        }


def grade_documents(state: AgentState) -> AgentState:
    """
    ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ ìˆëŠ”ì§€ LLM(gpt-4o-mini)ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ë…¸ë“œ (ê³ ë„í™”)
    ê´€ë ¨ ì—†ìœ¼ë©´ web_search=True ì„¤ì •
    
    Args:
        state: í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ
        
    Returns:
        ì—…ë°ì´íŠ¸ëœ ìƒíƒœ (web_search, is_relevant, loop_count í¬í•¨)
    """
    question = state.get("question", "")
    documents = state.get("documents", [])
    thought_process = state.get("thought_process", [])
    loop_count = state.get("loop_count", 0)
    
    # ë¬´í•œ ë£¨í”„ ë°©ì§€: ìµœëŒ€ 3íšŒê¹Œì§€ë§Œ ì¬ì‹œë„
    if loop_count >= 3:
        thought_process.append(f"âš ï¸ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ë„ë‹¬ ({loop_count}íšŒ)")
        return {
            "web_search": False,
            "is_relevant": "no",
            "loop_count": loop_count,
            "current_step": "ë‹µë³€ ìƒì„± ì¤‘...",
            "thought_process": thought_process
        }
    
    # ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ì›¹ ê²€ìƒ‰ í•„ìš”
    if not documents or len(documents) == 0:
        thought_process.append("âŒ ë¬¸ì„œ í‰ê°€: ë¬¸ì„œ ì—†ìŒ â†’ ì›¹ ê²€ìƒ‰ í•„ìš”")
        return {
            "web_search": True,
            "is_relevant": "no",
            "loop_count": loop_count + 1,
            "current_step": "ì›¹ ê²€ìƒ‰ ì¤‘...",
            "thought_process": thought_process
        }
    
    # ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
    documents_text = "\n\n".join([f"[ë¬¸ì„œ {i+1}]\n{doc}" for i, doc in enumerate(documents)])
    
    # LLMì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€
    evaluation_prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ê³¼ ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ê²€í† í•˜ê³ , ë¬¸ì„œë“¤ì´ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸°ì— ì¶©ë¶„í•œ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ í‰ê°€í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {question}

ê²€ìƒ‰ëœ ë¬¸ì„œë“¤:
{documents_text}

í‰ê°€ ê¸°ì¤€:
- ë¬¸ì„œë“¤ì´ ì§ˆë¬¸ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ì´ ìˆê³  ë‹µë³€ì— ì¶©ë¶„í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²½ìš°: "yes"
- ë¬¸ì„œë“¤ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ì—†ê±°ë‚˜ ë‹µë³€ì— í•„ìš”í•œ ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš°: "no"

ë‹µë³€ì€ ë°˜ë“œì‹œ "yes" ë˜ëŠ” "no"ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

    try:
        response = llm.invoke(evaluation_prompt)
        evaluation = response.content.strip().lower() if hasattr(response, 'content') else str(response).strip().lower()
        
        # "yes"ê°€ ì•„ë‹ˆë©´ ì›¹ ê²€ìƒ‰ í•„ìš”
        web_search_needed = not (evaluation.startswith("yes") or evaluation == "yes")
        is_relevant = "yes" if not web_search_needed else "no"
        
        if web_search_needed:
            thought_process.append(f"âŒ ë¬¸ì„œ í‰ê°€: ê´€ë ¨ì„± ë‚®ìŒ â†’ ì›¹ ê²€ìƒ‰ í•„ìš” ({loop_count + 1}íšŒ ì‹œë„)")
        else:
            thought_process.append("âœ… ë¬¸ì„œ í‰ê°€: ê´€ë ¨ì„± ë†’ìŒ â†’ ë‹µë³€ ìƒì„±")
            
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ í´ë°± (ì¡°ìš©íˆ ì²˜ë¦¬)
        web_search_needed = True
        is_relevant = "no"
        thought_process.append(f"âš ï¸ ë¬¸ì„œ í‰ê°€: ì˜¤ë¥˜ ë°œìƒ â†’ ì›¹ ê²€ìƒ‰ ì‹¤í–‰ ({loop_count + 1}íšŒ ì‹œë„)")
    
    return {
        "web_search": web_search_needed,
        "is_relevant": is_relevant,
        "loop_count": loop_count + 1 if web_search_needed else loop_count,
        "current_step": "ì›¹ ê²€ìƒ‰ ì¤‘..." if web_search_needed else "ë‹µë³€ ìƒì„± ì¤‘...",
        "thought_process": thought_process
    }


def web_search_node(state: AgentState) -> AgentState:
    """
    web_search=Trueì¼ ë•Œ Tavily APIë¡œ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë¬¸ì„œì— ì¶”ê°€í•˜ëŠ” ë…¸ë“œ (ê³ ë„í™”)
    í˜„ì¬ ì‹œê°„ ì •ë³´ë¥¼ ê²€ìƒ‰ ì¿¼ë¦¬ì— í¬í•¨í•˜ì—¬ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        state: í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ
        
    Returns:
        ì—…ë°ì´íŠ¸ëœ ìƒíƒœ (documentsì— ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€)
    """
    question = state.get("question", "")
    existing_documents = state.get("documents", [])
    thought_process = state.get("thought_process", [])
    
    if tavily_client is None:
        thought_process.append("âš ï¸ ì›¹ ê²€ìƒ‰: Tavily ë¯¸ì„¤ì • â†’ ìŠ¤í‚µ")
        return {
            "documents": existing_documents,
            "web_search": False,
            "current_step": "ë‹µë³€ ìƒì„± ì¤‘...",
            "thought_process": thought_process
        }
    
    try:
        # í˜„ì¬ ì‹œê°„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        now = datetime.now()
        current_date = now.strftime("%Yë…„ %mì›” %dì¼")
        current_time = now.strftime("%Hì‹œ %Më¶„")
        current_datetime_str = f"{current_date} {current_time}"
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ì— í˜„ì¬ ì‹œê°„ ì •ë³´ ì¶”ê°€ (ìµœì‹  ì •ë³´ ê²€ìƒ‰ì„ ìœ„í•´)
        enhanced_query = f"{question} (í˜„ì¬ ì‹œê°„: {current_datetime_str})"
        
        # Tavily ê²€ìƒ‰
        response = tavily_client.search(
            query=enhanced_query,
            max_results=3,
            search_depth="advanced"
        )
        
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¬¸ì„œì— ì¶”ê°€ (í˜„ì¬ ì‹œê°„ ì •ë³´ í¬í•¨)
        search_results = []
        for result in response.get("results", []):
            content = result.get("content", "")
            if content:
                # ê° ê²€ìƒ‰ ê²°ê³¼ì— í˜„ì¬ ì‹œê°„ ì •ë³´ ì¶”ê°€
                timestamped_content = f"[ê²€ìƒ‰ ì‹œê°„: {current_datetime_str}]\n{content}"
                search_results.append(timestamped_content)
        
        existing_documents.extend(search_results)
        thought_process.append(f"ğŸŒ ì›¹ ê²€ìƒ‰: {len(search_results)}ê°œ ê²°ê³¼ ì¶”ê°€ (ê²€ìƒ‰ ì‹œê°„: {current_datetime_str})")
    except Exception as e:
        # ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜ ì‹œ ê¸°ì¡´ ë¬¸ì„œ ìœ ì§€ (ì¡°ìš©íˆ ì²˜ë¦¬)
        thought_process.append("âš ï¸ ì›¹ ê²€ìƒ‰: ì˜¤ë¥˜ ë°œìƒ")
    
    return {
        "documents": existing_documents,
        "web_search": False,  # ì›¹ ê²€ìƒ‰ ì™„ë£Œ í›„ í”Œë˜ê·¸ ë¦¬ì…‹
        "current_step": "ë‹µë³€ ìƒì„± ì¤‘...",
        "thought_process": thought_process
    }


def generate(state: AgentState) -> AgentState:
    """
    í™•ë³´ëœ ë¬¸ì„œë“¤ì„ contextë¡œ ì‚¼ì•„ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë…¸ë“œ (ê³ ë„í™”)
    í˜„ì¬ ì‹œê°„ ì •ë³´ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨í•˜ì—¬ ì •í™•í•œ ì‹œê°„ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    
    Args:
        state: í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ
        
    Returns:
        ì—…ë°ì´íŠ¸ëœ ìƒíƒœ (messages, contextì— ë‹µë³€ ì¶”ê°€)
    """
    question = state.get("question", "")
    documents = state.get("documents", [])
    messages = state.get("messages", [])
    intent = state.get("intent", "factual")
    thought_process = state.get("thought_process", [])
    
    # í˜„ì¬ ì‹œê°„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    now = datetime.now()
    current_date = now.strftime("%Yë…„ %mì›” %dì¼")
    current_time = now.strftime("%Hì‹œ %Më¶„")
    current_datetime_str = f"{current_date} {current_time}"
    current_weekday = now.strftime("%A")  # ì˜ì–´ ìš”ì¼
    weekday_kr = {
        'Monday': 'ì›”ìš”ì¼',
        'Tuesday': 'í™”ìš”ì¼',
        'Wednesday': 'ìˆ˜ìš”ì¼',
        'Thursday': 'ëª©ìš”ì¼',
        'Friday': 'ê¸ˆìš”ì¼',
        'Saturday': 'í† ìš”ì¼',
        'Sunday': 'ì¼ìš”ì¼'
    }
    current_weekday_kr = weekday_kr.get(current_weekday, current_weekday)
    full_datetime_str = f"{current_date} {current_weekday_kr} {current_time}"
    
    # ë¬¸ì„œë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•©
    if documents:
        context_text = "\n\n".join([f"[ë¬¸ì„œ {i+1}]\n{doc}" for i, doc in enumerate(documents)])
        thought_process.append(f"ğŸ“ ë‹µë³€ ìƒì„±: {len(documents)}ê°œ ë¬¸ì„œ ê¸°ë°˜")
    else:
        context_text = "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        thought_process.append("ğŸ“ ë‹µë³€ ìƒì„±: ë¬¸ì„œ ì—†ìŒ (ì¼ë°˜ ì‘ë‹µ)")
    
    # ì˜ë„ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ì¡°ì •
    intent_instructions = {
        'factual': "ì •í™•í•œ ì‚¬ì‹¤ì„ ì œê³µí•˜ê³ , ì¶œì²˜ê°€ ëª…í™•í•œ ì •ë³´ë¥¼ ìš°ì„ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.",
        'analytical': "ë¹„êµ, ë¶„ì„, í‰ê°€ë¥¼ í†µí•´ ë‹¤ê°ë„ë¡œ ë‹µë³€í•˜ê³ , ì¥ë‹¨ì ì„ ê· í˜•ìˆê²Œ ì œì‹œí•˜ì„¸ìš”.",
        'conversational': "ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ì–´ì¡°ë¡œ ë‹µë³€í•˜ì„¸ìš”.",
        'procedural': "ë‹¨ê³„ë³„ë¡œ ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ê³ , ì‹¤í–‰ ê°€ëŠ¥í•œ ë°©ë²•ì„ ì œì‹œí•˜ì„¸ìš”."
    }
    intent_instruction = intent_instructions.get(intent, intent_instructions['factual'])
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„± (í˜„ì¬ ì‹œê°„ ì •ë³´ í¬í•¨)
    prompt = f"""ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

[ì¤‘ìš”: í˜„ì¬ ì‹œê°„ ì •ë³´]
í˜„ì¬ ì‹œê°„ì€ {full_datetime_str}ì…ë‹ˆë‹¤.
ì‹œê°„ ê´€ë ¨ ì§ˆë¬¸ì´ ìˆë‹¤ë©´ ì´ ì •ë³´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

[ë‹µë³€ ìŠ¤íƒ€ì¼]
{intent_instruction}

[ì»¨í…ìŠ¤íŠ¸]
{context_text}

[ì§ˆë¬¸]
{question}

[ë‹µë³€]
"""

    # LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±
    try:
        response = llm.invoke(prompt)
        answer = response.content if hasattr(response, 'content') else str(response)
        thought_process.append("âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        error_msg = str(e)
        
        # ë” ìì„¸í•œ ì—ëŸ¬ ë©”ì‹œì§€ ì œê³µ
        if "insufficient_quota" in error_msg or "429" in error_msg:
            answer = """âš ï¸ OpenAI API í• ë‹¹ëŸ‰ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

ê°€ëŠ¥í•œ ì›ì¸:
1. OpenAI ê³„ì •ì— í¬ë ˆë”§ì´ ì—†ìŠµë‹ˆë‹¤
   â†’ https://platform.openai.com/account/billing ì—ì„œ í¬ë ˆë”§ì„ í™•ì¸í•˜ì„¸ìš”
2. ë¬´ë£Œ í‹°ì–´ì˜ ê²½ìš° ì´ˆê¸° í¬ë ˆë”§ì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
   â†’ ê²°ì œ ìˆ˜ë‹¨ì„ ì¶”ê°€í•˜ê±°ë‚˜ í¬ë ˆë”§ì„ ì¶©ì „í•˜ì„¸ìš”
3. API í‚¤ê°€ ì˜ëª»ë˜ì—ˆê±°ë‚˜ ë‹¤ë¥¸ ê³„ì •ì˜ í‚¤ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤
   â†’ .env íŒŒì¼ì˜ OPENAI_API_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”"""
        elif "api_key" in error_msg.lower():
            answer = """âš ï¸ OpenAI API í‚¤ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

.env íŒŒì¼ì— ì˜¬ë°”ë¥¸ OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.
API í‚¤ëŠ” https://platform.openai.com/api-keys ì—ì„œ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."""
        else:
            answer = f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nì˜¤ë¥˜ ë‚´ìš©: {error_msg}"
    
    # ë©”ì‹œì§€ì— ì¶”ê°€
    updated_messages = messages + [
        HumanMessage(content=question),
        AIMessage(content=answer)
    ]
    
    return {
        "messages": updated_messages,
        "context": context_text,
        "current_step": "ì™„ë£Œ",
        "thought_process": thought_process
    }


def load_pdf_to_vectorstore(file_path: str, persist_directory: str = "./chroma_db"):
    """
    PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìª¼ê°œê³  ChromaDBì— ì €ì¥í•œ í›„ Retrieverë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        file_path: PDF íŒŒì¼ ê²½ë¡œ
        persist_directory: ChromaDB ì €ì¥ ë””ë ‰í† ë¦¬
        
    Returns:
        Retriever ê°ì²´
    """
    # PDF ë¡œë“œ
    loader = PyPDFLoader(file_path)
    documents = loader.load()
    
    # í…ìŠ¤íŠ¸ ë¶„í•  (Split)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    splits = text_splitter.split_documents(documents)
    
    # ChromaDB ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥
    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=embeddings,
        persist_directory=persist_directory
    )
    
    # Retriever ìƒì„± ë° ë°˜í™˜
    retriever = vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 3}
    )
    
    print(f"ë¬¸ì„œê°€ ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {len(splits)}ê°œ ì²­í¬")
    return retriever

